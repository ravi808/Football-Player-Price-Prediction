{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataframe using pandas\n",
    "data = pd.read_csv('footballPlayer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing value of region record as the most common value\n",
    "data['region'] = data['region'].fillna(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>club</th>\n",
       "      <th>age</th>\n",
       "      <th>position</th>\n",
       "      <th>position_cat</th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_value</th>\n",
       "      <th>fpl_sel</th>\n",
       "      <th>fpl_points</th>\n",
       "      <th>region</th>\n",
       "      <th>nationality</th>\n",
       "      <th>new_foreign</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>club_id</th>\n",
       "      <th>big_club</th>\n",
       "      <th>new_signing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexis Sanchez</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>LW</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4329</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.10%</td>\n",
       "      <td>264</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chile</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mesut Ozil</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>AM</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4395</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.60%</td>\n",
       "      <td>167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petr Cech</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>35</td>\n",
       "      <td>GK</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1529</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.90%</td>\n",
       "      <td>134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theo Walcott</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>28</td>\n",
       "      <td>RW</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2393</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50%</td>\n",
       "      <td>122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laurent Koscielny</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>31</td>\n",
       "      <td>CB</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>912</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name     club  age position  position_cat  market_value  \\\n",
       "0     Alexis Sanchez  Arsenal   28       LW             1          65.0   \n",
       "1         Mesut Ozil  Arsenal   28       AM             1          50.0   \n",
       "2          Petr Cech  Arsenal   35       GK             4           7.0   \n",
       "3       Theo Walcott  Arsenal   28       RW             1          20.0   \n",
       "4  Laurent Koscielny  Arsenal   31       CB             3          22.0   \n",
       "\n",
       "   page_views  fpl_value fpl_sel  fpl_points  region     nationality  \\\n",
       "0        4329       12.0  17.10%         264     3.0           Chile   \n",
       "1        4395        9.5   5.60%         167     2.0         Germany   \n",
       "2        1529        5.5   5.90%         134     2.0  Czech Republic   \n",
       "3        2393        7.5   1.50%         122     1.0         England   \n",
       "4         912        6.0   0.70%         121     2.0          France   \n",
       "\n",
       "   new_foreign  age_cat  club_id  big_club  new_signing  \n",
       "0            0        4        1         1            0  \n",
       "1            0        4        1         1            0  \n",
       "2            0        6        1         1            0  \n",
       "3            0        4        1         1            0  \n",
       "4            0        4        1         1            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    def __init__(self,data):\n",
    "        \n",
    "        self.data = data\n",
    "        self.cols_to_be_dropped = ['name','club_id','age_cat','nationality']\n",
    "        self.cols_to_be_encoded = ['club','position','position_cat','region']\n",
    "        \n",
    "    def addPosCat(self,inputCat):\n",
    "\n",
    "        if inputCat == 1:\n",
    "            return('Attackers')\n",
    "        elif inputCat == 2:\n",
    "            return('Midfielders')\n",
    "        elif inputCat == 3:\n",
    "            return('Defenders')\n",
    "        else:\n",
    "            return('Goalkeeper')\n",
    "        \n",
    "    def addRegion(self, inpregion):\n",
    "    \n",
    "        if inpregion == 1:\n",
    "            return('England')\n",
    "        elif inpregion == 2:\n",
    "            return('EU')\n",
    "        elif inpregion == 3:\n",
    "            return('Americans')\n",
    "        else:\n",
    "            return('Rest of World')\n",
    "        \n",
    "    def columnTypeConversion(self):\n",
    "        \n",
    "        # Converting fpl selection into numeric variable \n",
    "        self.data['fpl_sel'] = self.data['fpl_sel'].map(lambda x: str(x)[:-1]).astype('float')\n",
    "        \n",
    "    def logTransformation(self):\n",
    "        \n",
    "        # log transformation on page views variable as it has a high skew\n",
    "        self.data['page_views'] = self.data['page_views'].apply(np.log)\n",
    "        \n",
    "    # Encoding the categorical variables using pandas dummies \n",
    "    def dataEncoding(self):\n",
    "\n",
    "        self.data = pd.get_dummies(self.data, columns = self.cols_to_be_encoded, drop_first = True)\n",
    "        \n",
    "    def getProcessedData(self):\n",
    "        self.data = self.data.drop(self.cols_to_be_dropped, inplace = False, axis = 1)\n",
    "        self.data['position_cat'] = self.data['position_cat'].apply(self.addPosCat)\n",
    "        self.data['region'] = self.data['region'].apply(self.addRegion)\n",
    "        self.columnTypeConversion()\n",
    "        self.dataEncoding()\n",
    "        self.logTransformation()\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj = DataPreprocessing(data) \n",
    "encoded_data = data_obj.getProcessedData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>market_value</th>\n",
       "      <th>page_views</th>\n",
       "      <th>fpl_value</th>\n",
       "      <th>fpl_sel</th>\n",
       "      <th>fpl_points</th>\n",
       "      <th>new_foreign</th>\n",
       "      <th>big_club</th>\n",
       "      <th>new_signing</th>\n",
       "      <th>club_Bournemouth</th>\n",
       "      <th>...</th>\n",
       "      <th>position_RB</th>\n",
       "      <th>position_RM</th>\n",
       "      <th>position_RW</th>\n",
       "      <th>position_SS</th>\n",
       "      <th>position_cat_Defenders</th>\n",
       "      <th>position_cat_Goalkeeper</th>\n",
       "      <th>position_cat_Midfielders</th>\n",
       "      <th>region_EU</th>\n",
       "      <th>region_England</th>\n",
       "      <th>region_Rest of World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.373092</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.388223</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.332369</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.780303</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.815640</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  market_value  page_views  fpl_value  fpl_sel  fpl_points  new_foreign  \\\n",
       "0   28          65.0    8.373092       12.0     17.1         264            0   \n",
       "1   28          50.0    8.388223        9.5      5.6         167            0   \n",
       "2   35           7.0    7.332369        5.5      5.9         134            0   \n",
       "3   28          20.0    7.780303        7.5      1.5         122            0   \n",
       "4   31          22.0    6.815640        6.0      0.7         121            0   \n",
       "\n",
       "   big_club  new_signing  club_Bournemouth  ...  position_RB  position_RM  \\\n",
       "0         1            0                 0  ...            0            0   \n",
       "1         1            0                 0  ...            0            0   \n",
       "2         1            0                 0  ...            0            0   \n",
       "3         1            0                 0  ...            0            0   \n",
       "4         1            0                 0  ...            0            0   \n",
       "\n",
       "   position_RW  position_SS  position_cat_Defenders  position_cat_Goalkeeper  \\\n",
       "0            0            0                       0                        0   \n",
       "1            0            0                       0                        0   \n",
       "2            0            0                       0                        1   \n",
       "3            1            0                       0                        0   \n",
       "4            0            0                       1                        0   \n",
       "\n",
       "   position_cat_Midfielders  region_EU  region_England  region_Rest of World  \n",
       "0                         0          0               0                     0  \n",
       "1                         0          1               0                     0  \n",
       "2                         0          1               0                     0  \n",
       "3                         0          0               1                     0  \n",
       "4                         0          1               0                     0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_var = 'market_value'\n",
    "X = encoded_data[encoded_data.columns[~encoded_data.columns.isin([output_var])]]\n",
    "y = encoded_data[[output_var]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "x_train = x_train.reset_index(drop = True)\n",
    "x_test = x_test.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 45)\n",
      "(93, 45)\n",
      "(368, 1)\n",
      "(93, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performin min max scaling on input data\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score of training data - 0.8132510246370607\n",
      "Root Mean Square Error on training data - 5.436866832462385\n"
     ]
    }
   ],
   "source": [
    "# Fitting a Linear Regressor\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = lin_model.score(x_train, y_train)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "\n",
    "train_pred = lin_model.predict(x_train) \n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"Root Mean Square Error on training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculated cross validated scores\n",
    "\n",
    "def KFoldVerify(model, X, Y):\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    r2_scores = cross_val_score(model, X, Y, cv= cv, scoring = 'r2')\n",
    "    return r2_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.7344168512113418\n",
      "\n",
      "R^2 score of training data - 0.78040266256635\n",
      "Root Mean Square Error of training data - 5.895669325947489\n"
     ]
    }
   ],
   "source": [
    "# Fitting a Lasso Regressor\n",
    "lasso_model = Lasso(alpha=0.1, max_iter = 10000)\n",
    "cross_acc_train = KFoldVerify(lasso_model, x_train, y_train)\n",
    "lasso_model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = lasso_model.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = lasso_model.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.749958506436222\n",
      "\n",
      "R^2 score of training data - 0.8131100619440154\n",
      "Root Mean Square Error of training data - 5.438918385409342\n"
     ]
    }
   ],
   "source": [
    "# Fitting a Ridge Regressor\n",
    "ridge_model = Ridge(alpha=0.1,max_iter=10000)\n",
    "cross_acc_train = KFoldVerify(ridge_model, x_train, y_train)\n",
    "ridge_model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = ridge_model.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = ridge_model.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.5425771751753989\n",
      "\n",
      "R^2 score of training data - 0.9999999922453932\n",
      "Root Mean Square Error of training data - 0.0011078972274179782\n"
     ]
    }
   ],
   "source": [
    "# fitting a support vector regressor\n",
    "SVR_regr = SVR(C = 10000.0, epsilon=0.001, kernel='poly', degree=3)\n",
    "cross_acc_train = KFoldVerify(SVR_regr, x_train, y_train)\n",
    "SVR_regr.fit(x_train, y_train)\n",
    "\n",
    "acc_train = SVR_regr.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = SVR_regr.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbour Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.5423155619347894\n",
      "\n",
      "R^2 score of training data - 0.6409138332505087\n",
      "Root Mean Square Error of training data - 7.539089853239407\n"
     ]
    }
   ],
   "source": [
    "# fitting a nearest neighbour regressor\n",
    "K_neigh = KNeighborsRegressor(n_neighbors=10, metric='minkowski')\n",
    "cross_acc_train = KFoldVerify(K_neigh, x_train, y_train)\n",
    "K_neigh.fit(x_train, y_train)\n",
    "\n",
    "acc_train = K_neigh.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = K_neigh.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.4624770985842012\n",
      "\n",
      "R^2 score of training data - 0.8828557731831409\n",
      "Root Mean Square Error of training data - 4.306059505733762\n"
     ]
    }
   ],
   "source": [
    "# fitting a Decision Tree regressor\n",
    "tree_model = DecisionTreeRegressor(random_state = 0,max_depth=5)  \n",
    "cross_acc_train = KFoldVerify(tree_model, x_train, y_train)\n",
    "tree_model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = tree_model.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = tree_model.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.7206373221905318\n",
      "\n",
      "R^2 score of training data - 0.9050142592906198\n",
      "Root Mean Square Error of training data - 3.877473057559037\n"
     ]
    }
   ],
   "source": [
    "# fitting a random forest regressor\n",
    "Forest_regr = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "cross_acc_train = KFoldVerify(Forest_regr, x_train, y_train)\n",
    "Forest_regr.fit(x_train, y_train)\n",
    "\n",
    "acc_train = Forest_regr.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = Forest_regr.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.7745725339061129\n",
      "\n",
      "R^2 score of training data - 0.9657844389218845\n",
      "Root Mean Square Error of training data - 2.327187711500195\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 300,\n",
    "          'max_depth': 2,\n",
    "          'min_samples_split': 9,\n",
    "          'learning_rate': 0.1,\n",
    "          'loss': 'ls'}\n",
    "gbr_model = GradientBoostingRegressor(**params)\n",
    "cross_acc_train = KFoldVerify(gbr_model, x_train, y_train)\n",
    "gbr_model.fit(x_train, y_train)\n",
    "\n",
    "acc_train = gbr_model.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = gbr_model.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search is an effective method for adjusting the parameters in supervised learning and improve the generalization performance of a model. With Grid Search, we try all possible combinations of the parameters of interest and find the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.7603170914617032\n",
      "\n",
      "R^2 score of training data - 0.8123040923775416\n",
      "\n",
      "Lasso(alpha=0.01)\n"
     ]
    }
   ],
   "source": [
    "# For Lasso Regression\n",
    "params = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "lasso_reg = GridSearchCV(Lasso(), param_grid = params, cv = 5, scoring = 'r2')\n",
    "lasso_reg.fit(x_train, y_train)\n",
    "acc_train = lasso_reg.score(x_train, y_train)\n",
    "\n",
    "print(\"Cross Validation score - \" + str(lasso_reg.best_score_))\n",
    "print()\n",
    "\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print()\n",
    "\n",
    "print(lasso_reg.best_estimator_)\n",
    "lasso_best_params = lasso_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.7584133119888146\n",
      "\n",
      "R^2 score of training data - 0.8131100619440154\n",
      "\n",
      "Ridge(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "# For Ridge Regression\n",
    "params = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "ridge_reg = GridSearchCV(Ridge(), param_grid = params, cv = 5, scoring = 'r2')\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "acc_train = ridge_reg.score(x_train, y_train)\n",
    "\n",
    "print(\"Cross Validation score - \" + str(ridge_reg.best_score_))\n",
    "print()\n",
    "\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print()\n",
    "\n",
    "print(ridge_reg.best_estimator_)\n",
    "ridge_best_params = ridge_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.7108035616353691\n",
      "\n",
      "R^2 score of training data - 0.8723260521363837\n",
      "\n",
      "SVR(C=10, degree=2, epsilon=1, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# For Support Vector Regression\n",
    "params = [{'C': [1,10,100,1000,10000], 'epsilon': [0.0001,0.001,0.01,0.1,1],\n",
    "          'kernel': ['poly'], 'degree':[2,3,4]},\n",
    "          {'C': [1,10,100,1000,10000], 'epsilon': [0.0001,0.001,0.01,0.1,1],\n",
    "          'kernel': ['rbf']}]\n",
    "\n",
    "svr_reg = GridSearchCV(SVR(),param_grid = params, scoring = 'r2', cv = 5)\n",
    "svr_reg.fit(x_train,y_train)\n",
    "\n",
    "acc_train = svr_reg.score(x_train, y_train)\n",
    "\n",
    "print(\"Cross Validation score - \" + str(svr_reg.best_score_))\n",
    "print()\n",
    "\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print()\n",
    "\n",
    "print(svr_reg.best_estimator_)\n",
    "svr_best_params = svr_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.5552696160729681\n",
      "\n",
      "R^2 score of training data - 1.0\n",
      "\n",
      "KNeighborsRegressor(n_neighbors=15, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# For Nearest Neighbour Regression\n",
    "params = {'n_neighbors': [4,5,6,7,8,9,10,11,12,13,14,15], 'weights': ['uniform', 'distance']}\n",
    "\n",
    "knn_reg = GridSearchCV(KNeighborsRegressor(),param_grid = params, scoring = 'r2', cv = 5)\n",
    "knn_reg.fit(x_train,y_train)\n",
    "\n",
    "acc_train = knn_reg.score(x_train, y_train)\n",
    "\n",
    "print(\"Cross Validation score - \" + str(knn_reg.best_score_))\n",
    "print()\n",
    "\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print()\n",
    "\n",
    "print(knn_reg.best_estimator_)\n",
    "knn_best_params = knn_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.6592824899946654\n",
      "\n",
      "R^2 score of training data - 0.8968234546490297\n",
      "\n",
      "DecisionTreeRegressor(max_depth=12, min_samples_leaf=3, random_state=0,\n",
      "                      splitter='random')\n"
     ]
    }
   ],
   "source": [
    "# For Decision Tree Regression\n",
    "params  = {'splitter': ['best', 'random'],'min_samples_leaf': [1, 2 ,3],\n",
    "           'max_depth': [6,8,10,12,14,16,18]}\n",
    "\n",
    "tree_reg = GridSearchCV(DecisionTreeRegressor(random_state = 0) ,param_grid = params, scoring = 'r2', cv = 5)\n",
    "tree_reg.fit(x_train,y_train)\n",
    "\n",
    "acc_train = tree_reg.score(x_train, y_train)\n",
    "\n",
    "print(\"Cross Validation score - \" + str(tree_reg.best_score_))\n",
    "print()\n",
    "\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print()\n",
    "\n",
    "print(tree_reg.best_estimator_)\n",
    "tree_best_params = tree_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.772988568989313\n",
      "\n",
      "R^2 score of training data - 0.9685600187286247\n",
      "\n",
      "RandomForestRegressor(max_depth=16, max_features=0.3, n_estimators=50)\n"
     ]
    }
   ],
   "source": [
    "# For Random Forest Regression\n",
    "params = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [8, 10, 12, 14, 16],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'n_estimators': [40, 50, 60, 70],\n",
    "    'max_features': [0.3, 0.4, 0.5]\n",
    "}\n",
    "\n",
    "forest_reg = GridSearchCV(RandomForestRegressor(), param_grid = params, scoring = 'r2', cv = 5)\n",
    "forest_reg.fit(x_train,y_train)\n",
    "acc_train = forest_reg.score(x_train, y_train)\n",
    "\n",
    "print(\"Cross Validation score - \" + str(forest_reg.best_score_))\n",
    "print()\n",
    "\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print()\n",
    "print(forest_reg.best_estimator_)\n",
    "forest_best_params = forest_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score - 0.7673118274501264\n",
      "\n",
      "R^2 score of training data - 0.8571435712122726\n",
      "\n",
      "GradientBoostingRegressor(max_depth=16, min_samples_split=3, n_estimators=50,\n",
      "                          subsample=0.1)\n"
     ]
    }
   ],
   "source": [
    "# For Gradient Boosted Regression\n",
    "params = {'n_estimators': [50, 100, 200, 300],\n",
    "          'max_depth': [8,10,12,14,16],\n",
    "          'min_samples_split': [1,2,3],\n",
    "          'subsample':[0.1, 0.2]}\n",
    "\n",
    "gb_reg = GridSearchCV(GradientBoostingRegressor() ,param_grid = params, scoring = 'r2', cv = 5)\n",
    "gb_reg.fit(x_train,y_train)\n",
    "\n",
    "acc_train = gb_reg.score(x_train, y_train)\n",
    "\n",
    "print(\"Cross Validation score - \" + str(gb_reg.best_score_))\n",
    "print()\n",
    "\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print()\n",
    "\n",
    "print(gb_reg.best_estimator_)\n",
    "gb_best_params = gb_reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm :\n",
    "    \n",
    "    def __init__(self, num_chromosomes, num_genes):\n",
    "        self.num_chromosomes = num_chromosomes\n",
    "        self.num_genes = num_genes\n",
    "        self.population = np.random.uniform(low=-3.0, high=3.0, size=(self.num_chromosomes, self.num_genes))\n",
    "        \n",
    "    def crossOver(self, parent1_idx, parent2_idx):\n",
    "        Pc_threshold = 0.3\n",
    "        Pc = np.random.uniform(0,1)\n",
    "        \n",
    "        # If crossover probability is less than or equal to threshold then do crossover operation\n",
    "        if Pc <= Pc_threshold:\n",
    "            \n",
    "            # The point at which crossover takes place between two parents. Usually, it is at the center.\n",
    "            crossover_point = np.uint8(self.num_genes/2)\n",
    "            \n",
    "            # flipping the second halves of parent chromosomes\n",
    "            temp = self.population[parent1_idx, crossover_point:].copy()\n",
    "            self.population[parent1_idx, crossover_point:] = self.population[parent2_idx, crossover_point:]\n",
    "            self.population[parent2_idx, crossover_point:] = temp.copy()\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    def select_mating_pool(self, fitness_val):\n",
    "    \n",
    "        # Selecting the best individuals in the current generation as parents \n",
    "        # for producing the offspring of the next generation.\n",
    "        \n",
    "        select_probs  = fitness_val + 1\n",
    "        select_probs = select_probs / select_probs.sum()\n",
    "        fitness_based_selected =  np.random.choice(fitness_val.squeeze(), size = fitness_val.shape[0], \n",
    "                                                   replace = False, p = select_probs.squeeze())\n",
    "        \n",
    "        for i in range(fitness_based_selected.shape[0]//2):\n",
    "            parent_fit_1 = fitness_based_selected[(i*2)]\n",
    "            parent_fit_2 = fitness_based_selected[(i*2) + 1]\n",
    "            parent1_idx = np.where(fitness_val == parent_fit_1)[0][0]\n",
    "            parent2_idx = np.where(fitness_val == parent_fit_2)[0][0]\n",
    "            \n",
    "            # Doing Cross over operation\n",
    "            self.crossOver(parent1_idx, parent2_idx)\n",
    "            \n",
    "            # Doing Mutation Operation\n",
    "            self.mutation(parent1_idx, parent2_idx)\n",
    "            \n",
    "    \n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    def mutation(self, parent1_idx, parent2_idx):\n",
    "        Mc_threshold = 0.08\n",
    "        Mc = np.random.uniform(0,1)\n",
    "        \n",
    "        # If mutation probability is less than or equal to threshold then do mutation operation\n",
    "        if Mc <= Mc_threshold:\n",
    "            \n",
    "            # The random value to be added to the gene.\n",
    "            random_value = np.random.uniform(-1.0, 1.0, 1)\n",
    "            \n",
    "            # the random gene whose value is to be changed\n",
    "            gene_idx = np.random.randint(1,self.num_genes + 1, 1)\n",
    "            self.population[parent1_idx, gene_idx] = self.population[parent1_idx, gene_idx] + random_value\n",
    "            self.population[parent2_idx, gene_idx] = self.population[parent2_idx, gene_idx] + random_value\n",
    "            \n",
    "            \n",
    "        \n",
    "    def fitnessEvaluation(self, x_train, y_train):\n",
    "        fitness = np.zeros((self.population.shape[0],1))\n",
    "        for index, item in enumerate(self.population):\n",
    "            kfold = KFold(n_splits=5, random_state=2)\n",
    "            neigh = KNeighborsRegressor(n_neighbors= knn_best_params['n_neighbors'],\n",
    "                                        metric = 'wminkowski', metric_params = {'w':item})\n",
    "            fitness[index] = cross_val_score(neigh, x_train, y_train, cv=kfold, scoring=\"r2\").mean()\n",
    "        return fitness\n",
    "        \n",
    "    def generation(self, x_train, y_train):\n",
    "        num_generations = 10\n",
    "        for generation in range(num_generations):\n",
    "            # Measuring the fitness of each chromosome in the population\n",
    "            fitness_val = self.fitnessEvaluation(x_train, y_train)\n",
    "            # Selecting the best parents in the population for mating.\n",
    "            self.select_mating_pool(fitness_val)\n",
    "            \n",
    "        # returning the most fit chromosome and its fitness from the final population\n",
    "        return self.population[np.argmax(fitness_val)], np.max(fitness_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d73f5bda669e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGeneticAlgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The fitness value of fittest chromosome in the final population is \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-0c72e682ec2e>\u001b[0m in \u001b[0;36mgeneration\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;31m# Measuring the fitness of each chromosome in the population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mfitness_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitnessEvaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;31m# Selecting the best parents in the population for mating.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_mating_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-0c72e682ec2e>\u001b[0m in \u001b[0;36mfitnessEvaluation\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             neigh = KNeighborsRegressor(n_neighbors= knn_best_params['n_neighbors'],\n\u001b[0;32m     72\u001b[0m                                         metric = 'wminkowski', metric_params = {'w':item})\n",
      "\u001b[1;32mc:\\users\\ravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    427\u001b[0m                  random_state=None):\n\u001b[0;32m    428\u001b[0m         super().__init__(n_splits=n_splits, shuffle=shuffle,\n\u001b[1;32m--> 429\u001b[1;33m                          random_state=random_state)\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# None is the default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             raise ValueError(\n\u001b[1;32m--> 291\u001b[1;33m                 \u001b[1;34m'Setting a random_state has no effect since shuffle is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m                 \u001b[1;34m'False. You should leave '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m                 \u001b[1;34m'random_state to its default (None), or set shuffle=True.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True."
     ]
    }
   ],
   "source": [
    "obj = GeneticAlgorithm(20,45)\n",
    "wts, fitness = obj.generation(x_train, y_train)\n",
    "print(\"The fitness value of fittest chromosome in the final population is \"+ str(fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the weights learnt from the Genetic Algorithm in KNN regressor model to improve on its accuracy\n",
    "neigh = KNeighborsRegressor(n_neighbors=knn_best_params['n_neighbors'],\n",
    "                            metric = 'wminkowski', metric_params = {'w':wts})\n",
    "\n",
    "cross_acc_train = KFoldVerify(neigh, x_train, y_train)\n",
    "neigh.fit(x_train, y_train)\n",
    "\n",
    "acc_train = neigh.score(x_train, y_train)\n",
    "print(\"Cross Validation score - \" + str(cross_acc_train))\n",
    "print()\n",
    "\n",
    "\n",
    "train_pred = neigh.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train,train_pred)\n",
    "print(\"R^2 score of training data - \" + str(acc_train))\n",
    "print(\"Root Mean Square Error of training data - \" + str(mse_train**(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.DataFrame()\n",
    "reports['Models'] = ['Linear Regression', 'Lasso Regression', 'Ridge Regression', 'Support Vector Regression',\n",
    "                    'KNearestNeighbour Regression', 'DecisionTree Regression', 'RandomForest Regression',\n",
    "                    'GradientBoosted Regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating objects of each regression model with their best hyperparameter settings\n",
    "\n",
    "lr = LinearRegression()\n",
    "ls = Lasso(**lasso_best_params)\n",
    "rdg = Ridge(**ridge_best_params)\n",
    "svr = SVR(**svr_best_params)\n",
    "knn = KNeighborsRegressor(n_neighbors= knn_best_params['n_neighbors'],\n",
    "                          metric = 'wminkowski', metric_params = {'w':wts})\n",
    "dec_tree = DecisionTreeRegressor(**tree_best_params)\n",
    "ran_for = RandomForestRegressor(**forest_best_params)\n",
    "gbr = GradientBoostingRegressor(**gb_best_params)\n",
    "\n",
    "models_obj = [lr, ls, rdg, svr, knn, dec_tree, ran_for, gbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Cross Validation scores of best models\n",
    "cv = KFold(n_splits= 5,random_state= 1, shuffle=True)\n",
    "cross_val_scores = list(map(lambda model: round(cross_val_score(model,x_train, y_train, \n",
    "                                                                scoring = 'r2', cv = cv).mean(),2), models_obj))\n",
    "reports['Cross validated R^2 score'] = cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate r2 score and rmse on training data\n",
    "def scores_calculation(model):\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    r2_score = round(model.score(x_train, y_train),2)\n",
    "    train_pred = model.predict(x_train)\n",
    "    rmse = round(mean_squared_error(y_train, train_pred)**0.5, 2)\n",
    "    return r2_score, rmse\n",
    "\n",
    "scores = list(map(scores_calculation, models_obj))\n",
    "reports['Training R^2 scores'] = list(zip(*scores))[0]\n",
    "reports['Training RMSE'] = list(zip(*scores))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Clearly the best performing model is RandomForestRegression which has highest cross validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the best model and scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(ran_for, open('./model/model.pkl', 'wb'))\n",
    "pickle.dump(scaler, open('./model/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = ran_for.score(x_test, y_test)\n",
    "print('R^2 score on test data - '+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
